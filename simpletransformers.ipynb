{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "GermEval2021_ST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "induced-preference"
      },
      "source": [
        "!pip install -q simpletransformers emoji transformers --upgrade\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, plot_roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from ipywidgets import interact, widgets\n",
        "# Input Subtask\n",
        "print(\"1: Toxic Comment Classification\\n2: Engaging Comment Classification\\n3: Fact Claiming Comment Classification\\nChoose Subtask:\")\n",
        "TASK_NUMBER = int(input())"
      ],
      "id": "induced-preference",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acute-saturday"
      },
      "source": [
        "# load training dataset\n",
        "df = pd.read_csv('GermEval21_Translated_final.csv')\n",
        "df.columns\n",
        "df['English_Google'] = df['English_Google'].fillna(df['comment_text'])\n",
        "df['English_Google'] = df['English_Google'].apply(lambda x: np.str_(x))\n",
        "\n",
        "# load test dataset\n",
        "test_df = pd.read_csv('GermEval21_Test_Translated.csv')\n",
        "test_df.columns\n",
        "test_df['English_Google'] = test_df['English_Google'].fillna(test_df['c_text'])\n",
        "test_df['English_Google'] = test_df['English_Google'].apply(lambda x: np.str_(x))\n",
        "\n",
        "# load final test labels\n",
        "label_df = pd.read_csv('truth.csv')"
      ],
      "id": "acute-saturday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "universal-elimination"
      },
      "source": [
        "# split training dataset\n",
        "if TASK_NUMBER == 1:\n",
        "    print('='*50)\n",
        "    print(\"Subtask 1: Toxic Comment Classification\")\n",
        "    print('='*50)\n",
        "    df_eng = df.filter([\"English_Google\", \"Sub1_Toxic\"])\n",
        "    df_eng = df_eng.rename(columns={'English_Google' : 'text', 'Sub1_Toxic' : 'labels'})\n",
        "    trainn, testn = train_test_split(df_eng, test_size=0.2, stratify=df_eng['labels'], random_state=101)\n",
        "    testnn, valn = train_test_split(testn, test_size=0.5, stratify=testn['labels'], random_state=101)\n",
        "    df_ger = df.filter([\"comment_text\", \"Sub1_Toxic\"])\n",
        "    df_ger = df_ger.rename(columns={'comment_text' : 'text', 'Sub1_Toxic' : 'labels'})\n",
        "    traing, testg = train_test_split(df_ger, test_size=0.2, stratify=df_ger['labels'], random_state=101)\n",
        "    testng, valg = train_test_split(testg, test_size=0.5, stratify=testg['labels'], random_state=101)\n",
        "elif TASK_NUMBER == 2:\n",
        "    print('='*50)\n",
        "    print(\"Subtask 2: Engaging Comment Classification\")\n",
        "    print('='*50)\n",
        "    df_eng = df.filter([\"English_Google\", \"Sub2_Engaging\"])\n",
        "    df_eng = df_eng.rename(columns={'English_Google' : 'text', 'Sub2_Engaging' : 'labels'})\n",
        "    trainn, testn = train_test_split(df_eng, test_size=0.2, stratify=df_eng['labels'], random_state=101)\n",
        "    testnn, valn = train_test_split(testn, test_size=0.5, stratify=testn['labels'], random_state=101)\n",
        "    df_ger = df.filter([\"comment_text\", \"Sub2_Engaging\"])\n",
        "    df_ger = df_ger.rename(columns={'comment_text' : 'text', 'Sub2_Engaging' : 'labels'})\n",
        "    traing, testg = train_test_split(df_ger, test_size=0.2, stratify=df_ger['labels'], random_state=101)\n",
        "    testng, valg = train_test_split(testg, test_size=0.5, stratify=testg['labels'], random_state=101)\n",
        "elif TASK_NUMBER == 3:\n",
        "    print('='*50)\n",
        "    print(\"Subtask 3: Fact Claiming Comment Classification\")\n",
        "    print('='*50)\n",
        "    df_eng = df.filter([\"English_Google\", \"Sub3_FactClaiming\"])\n",
        "    df_eng = df_eng.rename(columns={'English_Google' : 'text', 'Sub3_FactClaiming' : 'labels'})\n",
        "    trainn, testn = train_test_split(df_eng, test_size=0.2, stratify=df_eng['labels'], random_state=101)\n",
        "    testnn, valn = train_test_split(testn, test_size=0.5, stratify=testn['labels'], random_state=101)\n",
        "    df_ger = df.filter([\"comment_text\", \"Sub3_FactClaiming\"])\n",
        "    df_ger = df_ger.rename(columns={'comment_text' : 'text', 'Sub3_FactClaiming' : 'labels'})\n",
        "    traing, testg = train_test_split(df_ger, test_size=0.2, stratify=df_ger['labels'], random_state=101)\n",
        "    testng, valg = train_test_split(testg, test_size=0.5, stratify=testg['labels'], random_state=101)\n",
        "\n",
        "# rename truth dataset\n",
        "if TASK_NUMBER == 1:\n",
        "    label_df = label_df.filter([\"English_Google\", \"Sub1_Toxic\"])\n",
        "    label_df = label_df.rename(columns={'English_Google' : 'text', 'Sub1_Toxic' : 'labels'})\n",
        "elif TASK_NUMBER == 2:\n",
        "    label_df = label_df.filter([\"English_Google\", \"Sub2_Engaging\"])\n",
        "    label_df = label_df.rename(columns={'English_Google' : 'text', 'Sub2_Engaging' : 'labels'})\n",
        "elif TASK_NUMBER == 3:\n",
        "    label_df = label_df.filter([\"English_Google\", \"Sub3_FactClaiming\"])\n",
        "    label_df = label_df.rename(columns={'English_Google' : 'text', 'Sub3_FactClaiming' : 'labels'})"
      ],
      "id": "universal-elimination",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applied-philadelphia"
      },
      "source": [
        "def evaluation_result(true, predicted):\n",
        "  print(f\"Accuracy Score: {round(accuracy_score(true,predicted) * 100,2)} %\\n\")\n",
        "  # accuracy\n",
        "  accuracy = accuracy_score(true,predicted)\n",
        "  print('Accuracy: %f' % accuracy)\n",
        "  # macro f1 \n",
        "  f1 = f1_score(true,predicted, average='macro')\n",
        "  print('F1 score: %f' % f1)\n",
        "  # ROC AUC\n",
        "  auc = roc_auc_score(true,predicted)\n",
        "  print('ROC AUC: %f' % auc)\n",
        "  # precision\n",
        "  precision = precision_score(true,predicted)\n",
        "  print('Precision: %f' % precision)\n",
        "  # recall\n",
        "  recall = recall_score(true,predicted)\n",
        "  print('Recall: %f' % recall)\n",
        "  # confusion matrix\n",
        "  matrix = confusion_matrix(true,predicted)\n",
        "  print(matrix)\n",
        "  # classification report\n",
        "  report = classification_report(true,predicted)\n",
        "  print(report)\n",
        "  print(\" \")\n",
        "    \n",
        "model_args ={'num_train_epochs': 3,\n",
        "             'train_batch_size': 16,\n",
        "             'eval_batch_size': 32,\n",
        "             'reprocess_input_data': True,\n",
        "             'overwrite_output_dir': True,\n",
        "             'evaluate_during_training': True,\n",
        "             'manual_seed': 101,\n",
        "             'use_multiprocessing': True,\n",
        "             'learning_rate': 4e-5}"
      ],
      "id": "applied-philadelphia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "communist-provider"
      },
      "source": [
        "# English BERTweet Base\n",
        "print('='*50)\n",
        "print('English BERTweet Base')\n",
        "print('-'*50)\n",
        "print(\" \")\n",
        "print('-'*50)\n",
        "print('Evaluation set')\n",
        "print('-'*50)\n",
        "model = ClassificationModel('bertweet', 'vinai/bertweet-base', args=model_args, use_cuda=True)\n",
        "model.train_model(trainn, eval_df=testnn, acc=accuracy_score)\n",
        "# eval\n",
        "predictor = model.predict(valn['text'].tolist())\n",
        "bertweet = predictor[0].tolist()\n",
        "true = valn['labels'].tolist()\n",
        "evaluation_result(true, bertweet)\n",
        "# test\n",
        "predictor = model.predict(test_df['English_Google'].tolist())\n",
        "bertweet = predictor[0].tolist()\n",
        "# after test labels released\n",
        "true = label_df['labels'].tolist()\n",
        "evaluation_result(true, bertweet)"
      ],
      "id": "communist-provider",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dedicated-cookie"
      },
      "source": [
        "# English XLM-T\n",
        "print('='*50)\n",
        "print('English cardiffnlp/twitter-xlm-roberta-base-sentiment')\n",
        "print('-'*50)\n",
        "print(\" \")\n",
        "model = ClassificationModel('xlmroberta', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', args=model_args, use_cuda=True)\n",
        "model.train_model(trainn, eval_df=testnn, acc=accuracy_score)\n",
        "predictor = model.predict(valn['text'].tolist())\n",
        "txlmr_en = predictor[0].tolist()\n",
        "true = valn['labels'].tolist()\n",
        "evaluation_result(true, txlmr_en)\n",
        "print(\" \")\n",
        "# test\n",
        "predictor = model.predict(test_df['English_Google'].tolist())\n",
        "txlmr_en = predictor[0].tolist()\n",
        "# after test labels released\n",
        "true = label_df['labels'].tolist()\n",
        "evaluation_result(true, txlmr_en)"
      ],
      "id": "dedicated-cookie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brown-helen"
      },
      "source": [
        "# German XLM-T\n",
        "print('='*50)\n",
        "print('German cardiffnlp/twitter-xlm-roberta-base-sentiment')\n",
        "print('-'*50)\n",
        "print(\" \")\n",
        "model = ClassificationModel('xlmroberta', 'cardiffnlp/twitter-xlm-roberta-base-sentiment', args=model_args, use_cuda=True)\n",
        "model.train_model(traing, eval_df=testng, acc=accuracy_score)\n",
        "predictor = model.predict(valg['text'].tolist())\n",
        "txlmr_de = predictor[0].tolist()\n",
        "true = valn['labels'].tolist()\n",
        "evaluation_result(true, txlmr_de)\n",
        "print(\" \")\n",
        "# test\n",
        "predictor = model.predict(test_df['c_text'].tolist())\n",
        "txlmr_de = predictor[0].tolist()\n",
        "# after test labels released\n",
        "true = label_df['labels'].tolist()\n",
        "evaluation_result(true, txlmr_de)"
      ],
      "id": "brown-helen",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "broke-independence"
      },
      "source": [
        "# English XLM-R Base\n",
        "print('='*50)\n",
        "print('English xlm-roberta-base')\n",
        "print('-'*50)\n",
        "print(\" \")\n",
        "model = ClassificationModel('xlmroberta', 'xlm-roberta-base', args=model_args, use_cuda=True)\n",
        "model.train_model(trainn, eval_df=testnn, acc=accuracy_score)\n",
        "predictor = model.predict(valn['text'].tolist())\n",
        "xlmr_en = predictor[0].tolist()\n",
        "true = valn['labels'].tolist()\n",
        "evaluation_result(true, xlmr_en)\n",
        "print(\" \")\n",
        "# test\n",
        "predictor = model.predict(test_df['English_Google'].tolist())\n",
        "xlmr_en = predictor[0].tolist()\n",
        "# after test labels released\n",
        "true = label_df['labels'].tolist()\n",
        "evaluation_result(true, xlmr_en)"
      ],
      "id": "broke-independence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spoken-railway"
      },
      "source": [
        "# German XLM-R Base\n",
        "print('='*50)\n",
        "print('German xlm-roberta-base')\n",
        "print('-'*50)\n",
        "print(\" \")\n",
        "model = ClassificationModel('xlmroberta', 'xlm-roberta-base', args=model_args, use_cuda=True)\n",
        "model.train_model(traing, eval_df=testng, acc=accuracy_score)\n",
        "predictor = model.predict(valg['text'].tolist())\n",
        "xlmr_de = predictor[0].tolist()\n",
        "true = valn['labels'].tolist()\n",
        "evaluation_result(true, xlmr_de)\n",
        "print(\" \")\n",
        "# test\n",
        "predictor = model.predict(test_df['c_text'].tolist())\n",
        "xlmr_de = predictor[0].tolist()\n",
        "# after test labels released\n",
        "true = label_df['labels'].tolist()\n",
        "evaluation_result(true, xlmr_de)"
      ],
      "id": "spoken-railway",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "certified-facing"
      },
      "source": [
        "data = pd.DataFrame([test_df['comment_id'].tolist(), bertweet, txlmr_en, txlmr_de, xlmr_en, xlmr_de]) #Each list would be added as a row\n",
        "data = data.transpose() #To Transpose and make each rows as columns\n",
        "data.columns=['comment_id', 'bertweet', 'txlmr_en', 'txlmr_de', 'xlmr_en', 'xlmr_de'] #Rename the columns\n",
        "\n",
        "display(data)"
      ],
      "id": "certified-facing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "completed-pointer"
      },
      "source": [
        "if TASK_NUMBER == 1:\n",
        "  data.to_csv('task1_ST.csv', index=False)\n",
        "elif TASK_NUMBER == 2:\n",
        "  data.to_csv('task2_ST.csv', index=False)\n",
        "elif TASK_NUMBER == 3:\n",
        "  data.to_csv('task3_ST.csv', index=False)"
      ],
      "id": "completed-pointer",
      "execution_count": null,
      "outputs": []
    }
  ]
}